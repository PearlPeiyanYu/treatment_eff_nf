{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import choice\n",
    "\n",
    "class simulate_data():\n",
    "\n",
    "    def __init__(self, n,d,sim,n_train):\n",
    "        super().__init__()\n",
    "        self.n = n\n",
    "        self.d = d\n",
    "        self.sim = sim\n",
    "        self.n_train = n_train\n",
    "        \n",
    "    def simulate_feature_vec(self, a=2):\n",
    "        if self.sim == 6:\n",
    "            self.x = x = np.random.uniform(0,1,(self.n,self.d))\n",
    "        else:\n",
    "            # Random states\n",
    "            def get_states(random_state, low, high, size):\n",
    "                rs = np.random.RandomState(random_state)\n",
    "                states = rs.randint(low=low, high=high, size=size)\n",
    "                return states \n",
    "            self.states1 = get_states(random_state=42, low=0, high=100000, size=self.d)\n",
    "            self.states2 = get_states(random_state=1028, low=0, high=100000, size=self.d)\n",
    "            # generate one sequence for raw covariance matrice\n",
    "            def generate_seq(i):\n",
    "                np.random.seed(self.states1[i])\n",
    "                a = np.random.randn(self.d)\n",
    "                np.random.seed(self.states2[i])\n",
    "                b = np.random.randn(1)\n",
    "                return a+b \n",
    "            # Generate random covariance matrice\n",
    "            A = np.matrix([generate_seq(i) for i in range(self.d)])\n",
    "            A = A*np.transpose(A)\n",
    "            D_half = np.diag(np.diag(A)**(-0.5))\n",
    "            C = D_half*A*D_half\n",
    "            # Generate d-dimensional feature vector\n",
    "            mean = np.zeros(self.d)\n",
    "            cov = C\n",
    "            self.x = np.random.multivariate_normal(mean, cov, self.n) # shape (n,d)\n",
    "\n",
    "    def generate_y_act(self):\n",
    "        \n",
    "        def simulate_y1():\n",
    "            # Generate error term matrice\n",
    "            e1 = np.random.randn(self.n)\n",
    "            e0 = np.random.randn(self.n)\n",
    "            # Generate mu\n",
    "            beta = np.random.uniform(-5,5,self.d)\n",
    "            mu0 = np.dot(self.x, beta) +5*(self.x[:,0] > 0.5) \n",
    "            mu1 = mu0 + 8*(self.x[:,1] > 0.1)\n",
    "            # Calculate y\n",
    "            self.y1 = mu1 + e1 # y1:treatement group #y0:control group  \n",
    "            self.y0 = mu0 + e0\n",
    "\n",
    "        def simulate_y2():\n",
    "            # Generate error term matrice\n",
    "            e1 = np.random.randn(self.n)\n",
    "            e0 = np.random.randn(self.n)\n",
    "            # Generate mu\n",
    "            beta0 = np.random.uniform(1,30,self.d)\n",
    "            beta1 = np.random.uniform(1,30,self.d)\n",
    "            mu0 = np.dot(self.x, beta0)\n",
    "            mu1 = np.dot(self.x, beta1)\n",
    "            # Calculate y\n",
    "            self.y1 = mu1 + e1\n",
    "            self.y0 = mu0 + e0\n",
    "\n",
    "        def simulate_y3():\n",
    "            # Generate error term matrice\n",
    "            e1 = np.random.randn(self.n)\n",
    "            e0 = np.random.randn(self.n)\n",
    "            # Generate mu\n",
    "            effect = 4 / (1+np.exp(-12 * ((self.x[:,0]-1)/2))) * (1+np.exp(-12 * ((self.x[:,1]-1)/2)))\n",
    "            mu1 = 0.5 * effect\n",
    "            mu0 = -mu1\n",
    "            # Calculate y\n",
    "            self.y1 = mu1 + e1\n",
    "            self.y0 = mu0 + e0\n",
    "\n",
    "        def simulate_y4():\n",
    "            # Generate error term matrice\n",
    "            e1 = np.random.randn(self.n)\n",
    "            e0 = np.random.randn(self.n)\n",
    "            # Generate mu\n",
    "            beta = np.random.uniform(1,30,self.d)\n",
    "            mu0 = np.dot(self.x, beta)\n",
    "            mu1 = mu0\n",
    "            # Calculate y\n",
    "            self.y1 = mu1 + e1\n",
    "            self.y0 = mu0 + e0\n",
    "\n",
    "        def simulate_y5():\n",
    "            # Generate error term matrice\n",
    "            e1 = np.random.randn(self.n)\n",
    "            e0 = np.random.randn(self.n)\n",
    "            # Generate mu\n",
    "            beta = np.random.uniform(-15,15,self.d)\n",
    "            beta_m_dim = min(self.d,5)\n",
    "            beta_m = beta[0:beta_m_dim]\n",
    "            mu0 = np.zeros(self.n)\n",
    "            mu0[self.x[:,19] < -0.4] = np.dot(self.x[self.x[:,19] < 0.-0.4][:,0:beta_m_dim],beta_m)\n",
    "            mu0[(self.x[:,19] < 0.4) & (self.x[:,19] >= -0.4)] = np.dot(self.x[(self.x[:,19] < 0.4) & (self.x[:,19] >= -0.4)][:,beta_m_dim:(2*beta_m_dim)],beta_m)\n",
    "            mu0[self.x[:,19] >= 0.4] = np.dot(self.x[self.x[:,19] >= 0.4][:,2*beta_m_dim:3*beta_m_dim],beta_m)\n",
    "            mu0 = np.dot(self.x, beta)\n",
    "            mu1 = mu0\n",
    "            # Calculate y\n",
    "            self.y1 = mu1 + e1\n",
    "            self.y0 = mu0 + e0\n",
    "        \n",
    "        def simulate_y6():\n",
    "            # Generate error term matrice\n",
    "            e1 = np.random.randn(self.n)\n",
    "            e0 = np.random.randn(self.n)\n",
    "            # Generate mu\n",
    "            mu0 = 2 * self.x[:,0] - 1\n",
    "            mu1 = mu0\n",
    "            # Calculate y\n",
    "            self.y1 = mu1 + e1\n",
    "            self.y0 = mu0 + e0\n",
    "    \n",
    "        if self.sim == 0:\n",
    "            simulate_y1()\n",
    "        elif self.sim == 1:\n",
    "            simulate_y1()\n",
    "        elif self.sim == 2:\n",
    "            simulate_y2()\n",
    "        elif self.sim == 3:\n",
    "            simulate_y3()\n",
    "        elif self.sim == 4:\n",
    "            simulate_y4()\n",
    "        elif self.sim == 5:\n",
    "            simulate_y5()\n",
    "        elif self.sim == 6:\n",
    "            simulate_y6()\n",
    "    \n",
    "    def simulate_assignment(self):\n",
    "        if self.sim == 6:\n",
    "            # Different propensity scores\n",
    "            prop_list = 1/4 * (1+ np.random.beta(2,4,self.n))\n",
    "            self.w = np.random.binomial(1,prop_list,self.n)\n",
    "        if self.sim == 0:\n",
    "            self.w = np.random.binomial(1,0.01,self.n)\n",
    "        else:\n",
    "            self.w = np.random.binomial(1,0.5,self.n)\n",
    "        \n",
    "    def generate_assigned_y(self):\n",
    "        self.y_obs = self.y1*self.w - self.y0*(self.w-1)\n",
    "        \n",
    "    def calculate_effect(self):\n",
    "        self.eff_act = self.y1 - self.y0\n",
    "    \n",
    "    def split_data(self):\n",
    "        self.x_train= self.x[:self.n_train,:]\n",
    "        self.y_obs_train =  self.y_obs[:self.n_train]\n",
    "        self.eff_act_train = self.eff_act[:self.n_train]\n",
    "        self.w_train = self.w[:self.n_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define forward process\n",
    "class M(nn.Module):\n",
    "    def __init__(self, n_feature,n_hidden, n_output = 1):\n",
    "        super(M, self).__init__() \n",
    "        self.hidden = nn.Linear(n_feature, n_hidden)\n",
    "        self.predict = nn.Linear(n_hidden, n_output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Here the forward pass is simply a linear function\n",
    "        x = F.relu(self.hidden(x))\n",
    "        x = self.predict(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Define Planar Flow\n",
    "class PlanarFlow(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(1, dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(1))\n",
    "        self.scale = nn.Parameter(torch.Tensor(1, dim))\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.weight.data.uniform_(-0.01, 0.01)\n",
    "        self.scale.data.uniform_(-0.01, 0.01)\n",
    "        self.bias.data.uniform_(-0.01, 0.01)\n",
    "\n",
    "    def forward(self, z):\n",
    "        activation = F.linear(z, self.weight, self.bias)\n",
    "        return z + self.scale * self.tanh(activation)\n",
    "\n",
    "# A helper class to compute the determinant of the gradient of the planar flow transformation.\n",
    "class PlanarFlowLogDetJacobian(nn.Module):\n",
    "    def __init__(self, affine):\n",
    "        super().__init__()\n",
    "        self.weight = affine.weight\n",
    "        self.bias = affine.bias\n",
    "        self.scale = affine.scale\n",
    "        self.tanh = affine.tanh\n",
    "\n",
    "    def forward(self, z):\n",
    "        activation = F.linear(z, self.weight, self.bias)\n",
    "        psi = (1 - self.tanh(activation) ** 2) * self.weight\n",
    "        det_grad = 1 + torch.mm(psi, self.scale.t())\n",
    "        def safe_log(z):\n",
    "            return torch.log(z + 1e-7)\n",
    "        return safe_log(det_grad.abs())\n",
    "    \n",
    "# Define Normalizing Flow class\n",
    "class NormalizingFlow(nn.Module):\n",
    "    def __init__(self, dim, flow_length):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, 30)\n",
    "        self.fc2 = nn.Linear(30, dim)\n",
    "        \n",
    "        self.transforms = nn.Sequential(*(\n",
    "            PlanarFlow(dim) for _ in range(flow_length)))\n",
    "        self.log_jacobians = nn.Sequential(*(\n",
    "            PlanarFlowLogDetJacobian(t) for t in self.transforms))\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.fc1(z))\n",
    "        z = F.relu(self.fc2(z))\n",
    "        \n",
    "        log_jacobians = []\n",
    "        for transform, log_jacobian in zip(self.transforms, self.log_jacobians):\n",
    "            log_jacobians.append(log_jacobian(z))\n",
    "            z = transform(z)\n",
    "        zk = z\n",
    "\n",
    "        return zk, log_jacobians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =simulate_data(500000, 20, sim=6, n_train=200000) #0,1,6 #5000, 10000, 25000, 50000, 100000, 200000\n",
    "data.simulate_feature_vec()\n",
    "data.generate_y_act()\n",
    "data.simulate_assignment()\n",
    "data.generate_assigned_y()\n",
    "data.calculate_effect()\n",
    "data.split_data()\n",
    "\n",
    "x_train = data.x_train\n",
    "y_obs_train = data.y_obs_train\n",
    "eff_act_train = data.eff_act_train  \n",
    "w_train = data.w_train\n",
    "\n",
    "x_trt_train = x_train[np.where(w_train == 1)]\n",
    "y_obs_trt_train = y_obs_train[np.where(w_train == 1)]\n",
    "w_trt_train = w_train[np.where(w_train == 1)]\n",
    "\n",
    "x_con_train= x_train[np.where(w_train == 0)]\n",
    "y_obs_con_train = y_obs_train[np.where(w_train == 0)]\n",
    "w_con_train = w_train[np.where(w_train == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 1.382171869277954\n",
      "epoch 100, loss 1.287340521812439\n",
      "epoch 200, loss 1.242877721786499\n",
      "epoch 300, loss 1.1855864524841309\n",
      "epoch 400, loss 1.1232715845108032\n"
     ]
    }
   ],
   "source": [
    "# Train M1 (treatment group)\n",
    "x_m1 = torch.from_numpy(x_trt_train).float() # default is requires_grad=True, no need to add this any more if pytorch version >= 0.4\n",
    "y_m1 = torch.from_numpy(y_obs_trt_train).float().unsqueeze(1)\n",
    "\n",
    "# Define model\n",
    "M_model1 = M(n_feature = 20,n_hidden =40, n_output =1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(M_model1.parameters(), lr = 0.01) #Stochastic Gradient Descent\n",
    "\n",
    "# Training\n",
    "for epoch in range(500):\n",
    "    outputs = M_model1(x_m1) \n",
    "    loss = criterion(outputs, y_m1)\n",
    "\n",
    "    optimizer1.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer1.step() # update gradients\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 1.3780337572097778\n",
      "epoch 100, loss 1.3005287647247314\n",
      "epoch 200, loss 1.2565492391586304\n",
      "epoch 300, loss 1.2031644582748413\n",
      "epoch 400, loss 1.1436454057693481\n"
     ]
    }
   ],
   "source": [
    "# Train M2 (control group)\n",
    "x_m0 = torch.from_numpy(x_con_train).float()\n",
    "y_m0 = torch.from_numpy(y_obs_con_train).float().unsqueeze(1)\n",
    "\n",
    "# Define model, loss function and optimizer\n",
    "M_model0 = M(n_feature = 20,n_hidden = 40, n_output = 1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer0 = torch.optim.SGD(M_model0.parameters(), lr = 0.01) #Stochastic Gradient Descent\n",
    "\n",
    "# Training\n",
    "for epoch in range(500):\n",
    "    outputs = M_model0(x_m0) \n",
    "    loss = criterion(outputs, y_m0)\n",
    "\n",
    "    optimizer0.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer0.step() # update gradients\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y0 for treatment group, y1 for control group\n",
    "y1_con_learnt = M_model1(x_m0).data.numpy()\n",
    "y0_trt_leant = M_model0(x_m1).data.numpy()\n",
    "\n",
    "# Impute D1, D0\n",
    "D1 = y_m1.data.numpy() - y0_trt_leant\n",
    "D0 = y1_con_learnt - y_m0.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.33990901708602905\n",
      "epoch 3, loss 0.33990901708602905\n",
      "epoch 6, loss 0.33990901708602905\n",
      "epoch 9, loss 0.33990901708602905\n"
     ]
    }
   ],
   "source": [
    "# Train f1(t,x) (treatment group)\n",
    "t_x_trt_train = torch.from_numpy(x_trt_train).float()\n",
    "t_D1 = torch.from_numpy(D1).float()\n",
    "t_eff = torch.from_numpy(eff_act_train[np.where(w_train == 1)]).float().unsqueeze(1)\n",
    "\n",
    "x_f1 = torch.cat((t_x_trt_train, t_D1),1)\n",
    "y_f1 = torch.cat((t_x_trt_train, t_eff),1)\n",
    "\n",
    "# Define Model\n",
    "M_flow1 = NormalizingFlow(dim=21, flow_length=16)\n",
    "optimizer = torch.optim.RMSprop(M_flow1.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    outputs,log_jacobians = M_flow1(x_f1) \n",
    "    loss = criterion(outputs, y_f1)\n",
    "\n",
    "    optimizer1.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer1.step() # update gradients\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.3772609233856201\n",
      "epoch 3, loss 0.3772609233856201\n",
      "epoch 6, loss 0.3772609233856201\n",
      "epoch 9, loss 0.3772609233856201\n"
     ]
    }
   ],
   "source": [
    "# Train f0(t,x) (control group)\n",
    "t_x_con_train = torch.from_numpy(x_con_train).float()\n",
    "t_D0 = torch.from_numpy(D0).float()\n",
    "t_eff_0 = torch.from_numpy(eff_act_train[np.where(w_train == 0)]).float().unsqueeze(1)\n",
    "\n",
    "x_f0 = torch.cat((t_x_con_train, t_D0),1)\n",
    "y_f0 = torch.cat((t_x_con_train, t_eff_0),1)\n",
    "\n",
    "# Define Model\n",
    "M_flow0 = NormalizingFlow(dim=21, flow_length=16)\n",
    "optimizer = torch.optim.RMSprop(M_flow0.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    outputs,log_jacobians = M_flow0(x_f0) \n",
    "    loss = criterion(outputs, y_f0)\n",
    "\n",
    "    optimizer1.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer1.step() # update gradients\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.286047101020813\n",
      "epoch 3, loss 0.286047101020813\n",
      "epoch 6, loss 0.286047101020813\n",
      "epoch 9, loss 0.286047101020813\n"
     ]
    }
   ],
   "source": [
    "# Train f1(x)\n",
    "x_1 = torch.from_numpy(x_trt_train).float()\n",
    "\n",
    "# Define Model\n",
    "M_evd1 = NormalizingFlow(dim=20, flow_length=16)\n",
    "optimizer = torch.optim.RMSprop(M_evd1.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    outputs,log_jacobians = M_evd1(x_1) \n",
    "    loss = criterion(outputs, x_1)\n",
    "\n",
    "    optimizer1.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer1.step() # update gradients\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 0.2748730480670929\n",
      "epoch 3, loss 0.2748730480670929\n",
      "epoch 6, loss 0.2748730480670929\n",
      "epoch 9, loss 0.2748730480670929\n"
     ]
    }
   ],
   "source": [
    "# Train f0(x) (control group)\\\n",
    "x_0 = torch.from_numpy(x_con_train).float()\n",
    "\n",
    "# Define Model\n",
    "M_evd0 = NormalizingFlow(dim=20, flow_length=16)\n",
    "optimizer = torch.optim.RMSprop(M_evd0.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    outputs,log_jacobians = M_evd0(x_0) \n",
    "    loss = criterion(outputs, x_0)\n",
    "\n",
    "    optimizer1.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer1.step() # update gradients\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3510784"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x_trt_train = torch.from_numpy(x_trt_train).float()\n",
    "t_D1 = torch.from_numpy(D1).float()\n",
    "x_1 = torch.cat((t_x_trt_train, t_D1),1)\n",
    "t_eff = torch.from_numpy(eff_act_train[np.where(w_train == 1)]).float().unsqueeze(1)\n",
    "y_1 = torch.cat((t_x_trt_train, t_eff),1)\n",
    "\n",
    "t_x_con_train = torch.from_numpy(x_con_train).float()\n",
    "t_D0 = torch.from_numpy(D0).float()\n",
    "x_0 = torch.cat((t_x_con_train, t_D0),1)\n",
    "t_eff_0 = torch.from_numpy(eff_act_train[np.where(w_train == 0)]).float().unsqueeze(1)\n",
    "y_0 = torch.cat((t_x_con_train, t_eff_0),1)\n",
    "\n",
    "x = torch.cat((x_1, x_0),0)\n",
    "x_b = torch.from_numpy(x_train).float()\n",
    "\n",
    "f1_t_x,log1 = M_flow1(x)#.data.numpy() #\n",
    "f0_t_x,log0 = M_flow0(x)#.data.numpy() #[:,-1]\n",
    "f1_x = M_evd1(x_b)\n",
    "f0_x = M_evd0(x_b)\n",
    "\n",
    "t1 = f1_t_x.data.numpy()#[:,-1]\n",
    "t0 = f0_t_x.data.numpy()#[:,-1]\n",
    "\n",
    "g = 0.5\n",
    "outputs = (g*t1 + (1-g)*t0) \n",
    "\n",
    "effect = np.concatenate((eff_act_train[np.where(w_train == 1)], eff_act_train[np.where(w_train == 0)]),0)\n",
    "\n",
    "eff = torch.cat((y_1, y_0),0)\n",
    "eff = eff.data.numpy()\n",
    "\n",
    "MSE = (np.square(outputs - eff)).mean(axis=None)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "## x-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99804, 1)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 1.1319682598114014\n",
      "epoch 100, loss 1.1319682598114014\n",
      "epoch 200, loss 1.1319682598114014\n",
      "epoch 300, loss 1.1319682598114014\n",
      "epoch 400, loss 1.1319682598114014\n"
     ]
    }
   ],
   "source": [
    "# Train M1 (treatment group)\n",
    "x_m1 = torch.from_numpy(x_trt_train).float() # default is requires_grad=True, no need to add this any more if pytorch version >= 0.4\n",
    "y_m1 = torch.from_numpy(D1).float()\n",
    "\n",
    "# Define model\n",
    "M_3 = M(n_feature = 20,n_hidden =40, n_output =1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer1 = torch.optim.SGD(M_model1.parameters(), lr = 0.01) #Stochastic Gradient Descent\n",
    "\n",
    "# Training\n",
    "for epoch in range(500):\n",
    "    outputs = M_3(x_m1) \n",
    "    loss = criterion(outputs, y_m1)\n",
    "\n",
    "    optimizer1.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer1.step() # update gradients\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 1.1540898084640503\n",
      "epoch 100, loss 1.1540898084640503\n",
      "epoch 200, loss 1.1540898084640503\n",
      "epoch 300, loss 1.1540898084640503\n",
      "epoch 400, loss 1.1540898084640503\n"
     ]
    }
   ],
   "source": [
    "# Train M2 (control group)\n",
    "x_m0 = torch.from_numpy(x_con_train).float()\n",
    "y_m0 = torch.from_numpy(D0).float()\n",
    "\n",
    "# Define model, loss function and optimizer\n",
    "M_4 = M(n_feature = 20,n_hidden = 40, n_output = 1)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer0 = torch.optim.SGD(M_model0.parameters(), lr = 0.01) #Stochastic Gradient Descent\n",
    "\n",
    "# Training\n",
    "for epoch in range(500):\n",
    "    outputs = M_4(x_m0) \n",
    "    loss = criterion(outputs, y_m0)\n",
    "\n",
    "    optimizer0.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer0.step() # update gradients\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0662393895778615"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat((x_1, x_0),0)\n",
    "x_b = torch.from_numpy(x_train).float()\n",
    "\n",
    "t1 = M_3(x_b).data.numpy()[:,-1]\n",
    "t0 = M_4(x_b).data.numpy()[:,-1]\n",
    "\n",
    "g = 0.5\n",
    "outputs = (g*t1 + (1-g)*t0) \n",
    "\n",
    "eff = torch.cat((y_1, y_0),0)\n",
    "eff = eff_act_train\n",
    "\n",
    "MSE = (np.square(outputs - eff)).mean(axis=None)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-165-7ae8447f81e8>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-165-7ae8447f81e8>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    5000 32.20489748888756 1.9970867649403918\u001b[0m\n\u001b[1;37m                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "x-nn\n",
    "5000 32.20489748888756 1.9970867649403918 \n",
    "10000 32.82145760036449 2.0472418014862903\n",
    "25000 30.141878200356224 0.36056638\n",
    "50000 30.141878200356224 0.34985852\n",
    "100000 31.830283975671097 2.000043453841319\n",
    "200000 31.335946136683184 2.0662393895778615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =simulate_data(500000, 20, sim=0, n_train=5000) #0,1,6 #5000, 10000, 25000, 50000, 100000, 200000\n",
    "data.simulate_feature_vec()\n",
    "data.generate_y_act()\n",
    "data.simulate_assignment()\n",
    "data.generate_assigned_y()\n",
    "data.calculate_effect()\n",
    "data.split_data()\n",
    "\n",
    "x_train = data.x_train\n",
    "y_obs_train = data.y_obs_train\n",
    "eff_act_train = data.eff_act_train  \n",
    "w_train = data.w_train\n",
    "\n",
    "x_trt_train = x_train[np.where(w_train == 1)]\n",
    "y_obs_trt_train = y_obs_train[np.where(w_train == 1)]\n",
    "w_trt_train = w_train[np.where(w_train == 1)]\n",
    "\n",
    "x_con_train= x_train[np.where(w_train == 0)]\n",
    "y_obs_con_train = y_obs_train[np.where(w_train == 0)]\n",
    "w_con_train = w_train[np.where(w_train == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_rf_0 = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "X_rf_1 = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "    \n",
    "X_rf_0.fit(x_con_train, y_obs_con_train)\n",
    "X_rf_1.fit(x_trt_train, y_obs_trt_train)\n",
    "    \n",
    "D1 = y_obs_trt_train - X_rf_0.predict(x_trt_train)\n",
    "D0 = X_rf_1.predict(x_con_train) - y_obs_con_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 2.1755123138427734\n",
      "epoch 3, loss 2.1755123138427734\n",
      "epoch 6, loss 2.1755123138427734\n",
      "epoch 9, loss 2.1755123138427734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "# Train f1(t,x) (treatment group)\n",
    "t_x_trt_train = torch.from_numpy(x_trt_train).float()\n",
    "t_D1 = torch.from_numpy(D1).float().unsqueeze(1)\n",
    "t_eff = torch.from_numpy(eff_act_train[np.where(w_train == 1)]).float().unsqueeze(1)\n",
    "\n",
    "x_f1 = torch.cat((t_x_trt_train, t_D1),1)\n",
    "y_f1 = torch.cat((t_x_trt_train, t_eff),1)\n",
    "\n",
    "# Define Model\n",
    "M_flow1 = NormalizingFlow(dim=21, flow_length=16)\n",
    "optimizer = torch.optim.RMSprop(M_flow1.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    outputs,log_jacobians = M_flow1(x_f1) \n",
    "    loss = criterion(outputs, y_f1)\n",
    "\n",
    "    optimizer1.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer1.step() # update gradients\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 2.7235121726989746\n",
      "epoch 3, loss 2.7235121726989746\n",
      "epoch 6, loss 2.7235121726989746\n",
      "epoch 9, loss 2.7235121726989746\n"
     ]
    }
   ],
   "source": [
    "# Train f0(t,x) (control group)\n",
    "t_x_con_train = torch.from_numpy(x_con_train).float()\n",
    "t_D0 = torch.from_numpy(D0).float().unsqueeze(1)\n",
    "t_eff_0 = torch.from_numpy(eff_act_train[np.where(w_train == 0)]).float().unsqueeze(1)\n",
    "\n",
    "x_f0 = torch.cat((t_x_con_train, t_D0),1)\n",
    "y_f0 = torch.cat((t_x_con_train, t_eff_0),1)\n",
    "\n",
    "# Define Model\n",
    "M_flow0 = NormalizingFlow(dim=21, flow_length=16)\n",
    "optimizer = torch.optim.RMSprop(M_flow0.parameters(), lr=0.01)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Training\n",
    "for epoch in range(10):\n",
    "    outputs,log_jacobians = M_flow0(x_f0) \n",
    "    loss = criterion(outputs, y_f0)\n",
    "\n",
    "    optimizer1.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # backprops\n",
    "    optimizer1.step() # update gradients\n",
    "\n",
    "    if epoch % 3 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch,loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4854677"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x_trt_train = torch.from_numpy(x_trt_train).float()\n",
    "t_D1 = torch.from_numpy(D1).float().unsqueeze(1)\n",
    "x_1 = torch.cat((t_x_trt_train, t_D1),1)\n",
    "t_eff = torch.from_numpy(eff_act_train[np.where(w_train == 1)]).float().unsqueeze(1)\n",
    "y_1 = torch.cat((t_x_trt_train, t_eff),1)\n",
    "\n",
    "t_x_con_train = torch.from_numpy(x_con_train).float()\n",
    "t_D0 = torch.from_numpy(D0).float().unsqueeze(1)\n",
    "x_0 = torch.cat((t_x_con_train, t_D0),1)\n",
    "t_eff_0 = torch.from_numpy(eff_act_train[np.where(w_train == 0)]).float().unsqueeze(1)\n",
    "y_0 = torch.cat((t_x_con_train, t_eff_0),1)\n",
    "\n",
    "x = torch.cat((x_1, x_0),0)\n",
    "x_b = torch.from_numpy(x_train).float()\n",
    "\n",
    "f1_t_x,log1 = M_flow1(x)#.data.numpy() #\n",
    "f0_t_x,log0 = M_flow0(x)#.data.numpy() #[:,-1]\n",
    "f1_x = M_evd1(x_b)\n",
    "f0_x = M_evd0(x_b)\n",
    "\n",
    "t1 = f1_t_x.data.numpy()#[:,-1]\n",
    "t0 = f0_t_x.data.numpy()#[:,-1]\n",
    "\n",
    "g = 0.5\n",
    "outputs = (g*t1 + (1-g)*t0) \n",
    "\n",
    "effect = np.concatenate((eff_act_train[np.where(w_train == 1)], eff_act_train[np.where(w_train == 0)]),0)\n",
    "\n",
    "eff = torch.cat((y_1, y_0),0)\n",
    "eff = eff.data.numpy()\n",
    "\n",
    "MSE = (np.square(outputs - eff)).mean(axis=None)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-293-3cbab3aff68d>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-293-3cbab3aff68d>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    5000 0.36664274\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "5000 2.4854677 0.36664274\n",
    "10000 2.5352986 0.32686228\n",
    "25000 2.4162445 0.35771015\n",
    "50000 2.4621582 0.35529676\n",
    "100000 2.4257748 0.32686228\n",
    "200000 2.4355667 0.35802394"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
