{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Simulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate d-dimensional feature vector\n",
    "def simulate_feature_vec(n, d, a=2):\n",
    "    # Random states\n",
    "    def get_states(random_state, low, high, size):\n",
    "        rs = np.random.RandomState(random_state)\n",
    "        states = rs.randint(low=low, high=high, size=size)\n",
    "        return states\n",
    "    states1 = get_states(random_state=42, low=0, high=100000, size=d)\n",
    "    states2 = get_states(random_state=1028, low=0, high=100000, size=d)    \n",
    "    # generate one sequence for raw covariance matrice\n",
    "    def generate_seq(i):\n",
    "        np.random.seed(states1[i])\n",
    "        a = np.random.randn(d)\n",
    "        np.random.seed(states2[i])\n",
    "        b = np.random.randn(1)\n",
    "        return a+b    \n",
    "    # Generate random covariance matrice\n",
    "    A = np.matrix([generate_seq(i) for i in range(d)])\n",
    "    A = A*np.transpose(A)\n",
    "    D_half = np.diag(np.diag(A)**(-0.5))\n",
    "    C = D_half*A*D_half\n",
    "    # Generate d-dimensional feature vector\n",
    "    mean = np.zeros(d)\n",
    "    cov = C\n",
    "    x = np.random.multivariate_normal(mean, cov, n) \n",
    "    return x # shape (n,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate potential outcomes\n",
    "def simulate_y1(n,d):\n",
    "    # Generate error term matrice\n",
    "    e1 = np.random.randn(n)\n",
    "    e0 = np.random.randn(n)\n",
    "    # Generate mu\n",
    "    beta = np.random.uniform(-5,5,d)\n",
    "    mu0 = np.dot(x, beta) +5*(x[:,0] > 0.5) \n",
    "    mu1 = mu0 + 8*(x[:,1] > 0.1)\n",
    "    # Calculate y\n",
    "    y1 = mu1 + e1\n",
    "    y0 = mu0 + e0\n",
    "    return y1,y0 # y1:treatement group #y0:control group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate potential outcomes\n",
    "def simulate_y2(n,d):\n",
    "    # Generate error term matrice\n",
    "    e1 = np.random.randn(n)\n",
    "    e0 = np.random.randn(n)\n",
    "    # Generate mu\n",
    "    beta0 = np.random.uniform(1,30,d)\n",
    "    beta1 = np.random.uniform(1,30,d)\n",
    "    mu0 = np.dot(x, beta0)\n",
    "    mu1 = np.dot(x, beta1)\n",
    "    # Calculate y\n",
    "    y1 = mu1 + e1\n",
    "    y0 = mu0 + e0\n",
    "    return y1,y0 # y1:treatement group #y0:control group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate potential outcomes\n",
    "def simulate_y3(n,d):\n",
    "    # Generate error term matrice\n",
    "    e1 = np.random.randn(n)\n",
    "    e0 = np.random.randn(n)\n",
    "    # Generate mu\n",
    "    effect = 4 / (1+np.exp(-12 * ((x[:,0]-1)/2))) * (1+np.exp(-12 * ((x[:,1]-1)/2)))\n",
    "    mu1 = 0.5 * effect\n",
    "    mu0 = -mu1\n",
    "    # Calculate y\n",
    "    y1 = mu1 + e1\n",
    "    y0 = mu0 + e0\n",
    "    return y1,y0 # y1:treatement group #y0:control group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate potential outcomes\n",
    "def simulate_y4(n,d):\n",
    "    # Generate error term matrice\n",
    "    e1 = np.random.randn(n)\n",
    "    e0 = np.random.randn(n)\n",
    "    # Generate mu\n",
    "    beta = np.random.uniform(1,30,d)\n",
    "    mu0 = np.dot(x, beta)\n",
    "    mu1 = mu0\n",
    "    # Calculate y\n",
    "    y1 = mu1 + e1\n",
    "    y0 = mu0 + e0\n",
    "    return y1,y0 # y1:treatement group #y0:control group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate potential outcomes\n",
    "def simulate_y5(n,d):\n",
    "    # Generate error term matrice\n",
    "    e1 = np.random.randn(n)\n",
    "    e0 = np.random.randn(n)\n",
    "    # Generate mu\n",
    "    beta = np.random.uniform(-15,15,d)\n",
    "    beta_m_dim = min(d,5)\n",
    "    beta_m = beta[0:beta_m_dim]\n",
    "    mu0 = np.zeros(n)\n",
    "    mu0[x[:,19] < -0.4] = np.dot(x[x[:,19] < 0.-0.4][:,0:beta_m_dim],beta_m)\n",
    "    mu0[(x[:,19] < 0.4) & (x[:,19] >= -0.4)] = np.dot(x[(x[:,19] < 0.4) & (x[:,19] >= -0.4)][:,beta_m_dim:(2*beta_m_dim)],beta_m)\n",
    "    mu0[x[:,19] >= 0.4] = np.dot(x[x[:,19] >= 0.4][:,2*beta_m_dim:3*beta_m_dim],beta_m)\n",
    "    mu0 = np.dot(x, beta)\n",
    "    mu1 = mu0\n",
    "    # Calculate y\n",
    "    y1 = mu1 + e1\n",
    "    y0 = mu0 + e0\n",
    "    return y1,y0 # y1:treatement group #y0:control group  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate potential outcomes\n",
    "def simulate_y6(n,d):\n",
    "    # Generate error term matrice\n",
    "    e1 = np.random.randn(n)\n",
    "    e0 = np.random.randn(n)\n",
    "    # Generate mu\n",
    "    mu0 = 2 * x[:,0] - 1\n",
    "    mu1 = mu0\n",
    "    # Calculate y\n",
    "    y1 = mu1 + e1\n",
    "    y0 = mu0 + e0\n",
    "    return y1,y0 # y1:treatement group #y0:control group "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate treatment assignment\n",
    "def simulate_assignment(propensity):\n",
    "    w = np.random.binomial(1,propensity,n)\n",
    "    return w\n",
    "\n",
    "# Different propensity scores\n",
    "def simulate_assignment_y6(n):\n",
    "    prop_list = 1/4 * (1+ np.random.beta(2,4,n))\n",
    "    w = np.random.binomial(1,prop_list,n)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate assigned y\n",
    "def generate_assigned_y(y1,y0,w):\n",
    "    y_obs = y1*w - y0*(w-1)\n",
    "    return y_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate effect\n",
    "def calculate_effect(y1, y0):\n",
    "    eff_act = y1 - y0\n",
    "    return eff_act"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give parameters and generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation_1_a: Unbalanced\n",
    "# Parameters\n",
    "n = 500000 # number of samples \n",
    "d = 20 # dimentionality of Xi\n",
    "a = 2 # Concentration of covariance matrix 1, -1,0\n",
    "propensity = 0.01 # propensity score of Bernouli distribution of Y\n",
    "\n",
    "# Generate data\n",
    "x = simulate_feature_vec(n,d) \n",
    "y1, y0 = simulate_y0(n,d)\n",
    "w = simulate_assignment(propensity)\n",
    "y_obs = generate_assigned_y(y1,y0,w)\n",
    "eff_act = calculate_effect(y1, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation_1_b: Unbalanced\n",
    "# Parameters\n",
    "n = 500000 # number of samples \n",
    "d = 20 # dimentionality of Xi\n",
    "a = 2 # Concentration of covariance matrix 1, -1,0\n",
    "propensity = 0.5 # propensity score of Bernouli distribution of Y\n",
    "\n",
    "# Generate data\n",
    "x = simulate_feature_vec(n,d) \n",
    "y1, y0 = simulate_y1(n,d)\n",
    "w = simulate_assignment(propensity)\n",
    "y_obs = generate_assigned_y(y1,y0,w)\n",
    "eff_act = calculate_effect(y1, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation_2\n",
    "# Parameters\n",
    "n = 500000 # number of samples \n",
    "d = 20 # dimentionality of Xi\n",
    "a = 2 # Concentration of covariance matrix 1, -1,0\n",
    "propensity = 0.5 # propensity score of Bernouli distribution of Y\n",
    "\n",
    "# Generate data\n",
    "x = simulate_feature_vec(n,d) \n",
    "y1, y0 = simulate_y2(n,d)\n",
    "w = simulate_assignment(propensity)\n",
    "y_obs = generate_assigned_y(y1,y0,w)\n",
    "eff_act = calculate_effect(y1, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation_3\n",
    "# Parameters\n",
    "n = 500000 # number of samples \n",
    "d = 20 # dimentionality of Xi\n",
    "a = 2 # Concentration of covariance matrix 1, -1,0\n",
    "propensity = 0.5 # propensity score of Bernouli distribution of Y\n",
    "\n",
    "# Generate data\n",
    "x = simulate_feature_vec(n,d) \n",
    "y1, y0 = simulate_y3(n,d)\n",
    "w = simulate_assignment(propensity)\n",
    "y_obs = generate_assigned_y(y1,y0,w)\n",
    "eff_act = calculate_effect(y1, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation_4\n",
    "# Parameters\n",
    "n = 500000 # number of samples \n",
    "d = 20 # dimentionality of Xi\n",
    "a = 2 # Concentr ation of covariance matrix 1, -1,0\n",
    "propensity = 0.5 # propensity score of Bernouli distribution of Y\n",
    "\n",
    "# Generate data\n",
    "x = simulate_feature_vec(n,d) \n",
    "y1, y0 = simulate_y4(n,d)\n",
    "w = simulate_assignment(propensity)\n",
    "y_obs = generate_assigned_y(y1,y0,w)\n",
    "eff_act = calculate_effect(y1, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation_5\n",
    "# Parameters\n",
    "n = 500000 # number of samples \n",
    "d = 20 # dimentionality of Xi\n",
    "a = 2 # Concentration of covariance matrix 1, -1,0\n",
    "propensity = 0.5 # propensity score of Bernouli distribution of Y\n",
    "\n",
    "# Generate data\n",
    "x = simulate_feature_vec(n,d) \n",
    "y1, y0 = simulate_y5(n,d)\n",
    "w = simulate_assignment(propensity)\n",
    "y_obs = generate_assigned_y(y1,y0,w)\n",
    "eff_act = calculate_effect(y1, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation_6\n",
    "# Parameters\n",
    "n = 500000 # number of samples \n",
    "d = 20 # dimentionality of Xi\n",
    "a = 2 # Concentration of covariance matrix 1, -1,0\n",
    "\n",
    "# Generate Data\n",
    "x = np.random.uniform(0,1,(n,d)) \n",
    "y1, y0 = simulate_y6(n,d)\n",
    "w = simulate_assignment_y6(n)\n",
    "y_obs = generate_assigned_y(y1,y0,w)\n",
    "eff_act = calculate_effect(y1, y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from bartpy.sklearnmodel import SklearnModel\n",
    "\n",
    "train_lens = [5000, 10000, 25000, 50000 100000, 200000]\n",
    "d = 20 # dimentionality of Xi\n",
    "a = 2 # Concentration of covariance matrix 1, -1,0\n",
    "propensity = 0.01 # propensity score of Bernouli distribution of Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\joblib\\disk.py:122: UserWarning: Unable to delete folder C:\\Users\\yupei\\AppData\\Local\\Temp\\joblib_memmapping_folder_15156_2281746886 after 5 tentatives.\n",
      "  .format(folder_path, RM_SUBDIRS_N_RETRY))\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\yupei\\\\AppData\\\\Local\\\\Temp\\\\joblib_memmapping_folder_15156_2281746886\\\\15156-2543474100096-b8086ff43e4a4ca88cadc6b53cc13d1d.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-09bf187bed08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mS_bart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSklearnModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mS_bart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS_bart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\bartpy\\sklearnmodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mself\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mparameter\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \"\"\"\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelayed_chains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prediction_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_combine_chains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    938\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    939\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 940\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    941\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    942\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pickle_cache\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_terminate_backend\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_terminate_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 696\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mterminate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;31m# in latter calls but we free as much memory as we can by deleting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[1;31m# the shared memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdelete_folder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_temp_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_workers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\joblib\\disk.py\u001b[0m in \u001b[0;36mdelete_folder\u001b[1;34m(folder_path, onerror)\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m                     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWindowsError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror)\u001b[0m\n\u001b[0;32m    505\u001b[0m             \u001b[1;31m# can't continue even if onerror hook returns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m             \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_rmtree_unsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0monerror\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[1;31m# Allow introspection of whether or not the hardening against symlink\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    389\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    392\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onerror)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfullname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    390\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                 \u001b[0monerror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfullname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\\\\Users\\\\yupei\\\\AppData\\\\Local\\\\Temp\\\\joblib_memmapping_folder_15156_2281746886\\\\15156-2543474100096-b8086ff43e4a4ca88cadc6b53cc13d1d.pkl'"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "MSE = []\n",
    "for n in train_lens:\n",
    "    \n",
    "    x = simulate_feature_vec(n,d) \n",
    "    y1, y0 = simulate_y1(n,d)\n",
    "    w = simulate_assignment(propensity)\n",
    "    y_obs = generate_assigned_y(y1,y0,w)\n",
    "    eff_act = calculate_effect(y1, y0)\n",
    "    \n",
    "    Y = np.array([y0[i] if w[i] else y1[i] for i in range(len(w))]).reshape((n,1)) # get Y for training\n",
    "    W = w.reshape((w.shape[0], 1))\n",
    "    X = np.concatenate((x, W),axis=1)\n",
    "    \n",
    "    x_train, y_train = X, Y\n",
    "\n",
    "    S_bart = SklearnModel()\n",
    "    S_bart.fit(x_train, y_train)\n",
    "    models.append(S_bart)\n",
    "    \n",
    "    w0 = np.zeros((w.shape[0], 1))\n",
    "    w1 = np.ones((w.shape[0], 1))\n",
    "    X0 = np.concatenate((x, w0),axis=1)\n",
    "    X1 = np.concatenate((x, w1),axis=1)\n",
    "    \n",
    "    y_true = y1 - y0\n",
    "    y0_pred = S_bart.predict(x_train)\n",
    "    y1_pred = S_bart.predict(x_train)\n",
    "    y_pred = y1_pred - y0_pred\n",
    "    mse_train = mean_squared_error(y_true, y_pred)\n",
    "    MSE.append(mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S-RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "C:\\Users\\yupei\\AppData\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "MSE = []\n",
    "for n in train_lens:\n",
    "    \n",
    "    x = simulate_feature_vec(n,d) \n",
    "    y1, y0 = simulate_y1(n,d)\n",
    "    w = simulate_assignment(propensity)\n",
    "    y_obs = generate_assigned_y(y1,y0,w)\n",
    "    eff_act = calculate_effect(y1, y0)\n",
    "    \n",
    "    Y = np.array([y0[i] if w[i] else y1[i] for i in range(len(w))]).reshape((n,1)) # get Y for training\n",
    "    W = w.reshape((w.shape[0], 1))\n",
    "    X = np.concatenate((x, W),axis=1)\n",
    "    \n",
    "    x_train, y_train = X, Y\n",
    "\n",
    "    S_rf = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "    S_rf.fit(x_train, y_train)\n",
    "    models.append(S_rf)\n",
    "    \n",
    "    w0 = np.zeros((w.shape[0], 1))\n",
    "    w1 = np.ones((w.shape[0], 1))\n",
    "    X0 = np.concatenate((x, w0),axis=1)\n",
    "    X1 = np.concatenate((x, w1),axis=1)\n",
    "    \n",
    "    y_true = y1 - y0\n",
    "    y0_pred = S_rf.predict(x_train)\n",
    "    y1_pred = S_rf.predict(x_train)\n",
    "    y_pred = y1_pred - y0_pred\n",
    "    mse_train = mean_squared_error(y_true, y_pred)\n",
    "    MSE.append(mse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31.68189511573245,\n",
       " 31.470518600739002,\n",
       " 31.720425264119623,\n",
       " 31.5131149796114,\n",
       " 31.478653786350517]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "MSE = []\n",
    "for n in train_lens:\n",
    "    \n",
    "    x = simulate_feature_vec(n,d) \n",
    "    y1, y0 = simulate_y1(n,d)\n",
    "    w = simulate_assignment(propensity)\n",
    "    y_obs = generate_assigned_y(y1,y0,w)\n",
    "    eff_act = calculate_effect(y1, y0)\n",
    "    \n",
    "    X_0 = np.array([x[i] for i in range(len(w)) if not w[i]])\n",
    "    X_1 = np.array([x[i] for i in range(len(w)) if w[i]])\n",
    "\n",
    "    Y_0 = np.array([y0[i] for i in range(len(w)) if not w[i]])\n",
    "    Y_1 = np.array([y1[i] for i in range(len(w)) if  w[i]])\n",
    "    \n",
    "    T_bart_0 = SklearnModel()\n",
    "    T_bart_1 = SklearnModel()\n",
    "    \n",
    "    T_bart_0.fit(X_0, Y_0)\n",
    "    T_bart_1.fit(X_1, Y_1)\n",
    "    \n",
    "    y0_pred = T_bart_0.predict(x)\n",
    "    y1_pred = T_bart_1.predict(x)\n",
    "    y_pred = y1_pred - y0_pred\n",
    "    y_true = y1 - y0\n",
    "    \n",
    "    mse = mean_squared_error(y_pred, y_true)\n",
    "    models.append((T_rt_0, T_rt_1))\n",
    "    MSE.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## T-RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "MSE = []\n",
    "for n in train_lens:\n",
    "    \n",
    "    x = simulate_feature_vec(n,d) \n",
    "    y1, y0 = simulate_y1(n,d)\n",
    "    w = simulate_assignment(propensity)\n",
    "    y_obs = generate_assigned_y(y1,y0,w)\n",
    "    eff_act = calculate_effect(y1, y0)\n",
    "    \n",
    "    X_0 = np.array([x[i] for i in range(len(w)) if not w[i]])\n",
    "    X_1 = np.array([x[i] for i in range(len(w)) if w[i]])\n",
    "\n",
    "    Y_0 = np.array([y0[i] for i in range(len(w)) if not w[i]])\n",
    "    Y_1 = np.array([y1[i] for i in range(len(w)) if  w[i]])\n",
    "    \n",
    "    T_rf_0 = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "    T_rf_1 = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "    \n",
    "    T_rf_0.fit(X_0, Y_0)\n",
    "    T_rf_1.fit(X_1, Y_1)\n",
    "    \n",
    "    y0_pred = T_rf_0.predict(x)\n",
    "    y1_pred = T_rf_1.predict(x)\n",
    "    y_pred = y1_pred - y0_pred\n",
    "    y_true = y1 - y0\n",
    "    \n",
    "    mse = mean_squared_error(y_pred, y_true)\n",
    "    models.append((T_rf_0, T_rf_1))\n",
    "    MSE.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30.957384283878458,\n",
       " 39.82619269509149,\n",
       " 35.590800811454805,\n",
       " 12.3637527644378,\n",
       " 16.933560936625103]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "MSE = []\n",
    "for n in train_lens:\n",
    "    \n",
    "    x = simulate_feature_vec(n,d) \n",
    "    y1, y0 = simulate_y1(n,d)\n",
    "    w = simulate_assignment(propensity)\n",
    "    y_obs = generate_assigned_y(y1,y0,w)\n",
    "    eff_act = calculate_effect(y1, y0)\n",
    "    \n",
    "    X_0 = np.array([x[i] for i in range(len(w)) if not w[i]])\n",
    "    X_1 = np.array([x[i] for i in range(len(w)) if w[i]])\n",
    "\n",
    "    Y_0 = np.array([y0[i] for i in range(len(w)) if not w[i]])\n",
    "    Y_1 = np.array([y1[i] for i in range(len(w)) if  w[i]])\n",
    "    \n",
    "    X_bart_0 = SklearnModel()\n",
    "    X_bart_1 = SklearnModel()\n",
    "    \n",
    "    X_bart_0.fit(X_0, Y_0)\n",
    "    X_bart_1.fit(X_1, Y_1)\n",
    "    \n",
    "    D_1 = Y_1 - X_rf_0.predict(X_1)\n",
    "    D_0 = X_bart_1.predict(X_0) - Y_0\n",
    "\n",
    "    X_bart_3 = SklearnModel()\n",
    "    X_bart_4 = SklearnModel()\n",
    "    \n",
    "    X_bart_3.fit(X_1, D_1)\n",
    "    X_bart_4.fit(X_0, D_0)\n",
    "    \n",
    "    \n",
    "    y1_pred = X_bart_3.predict(x)\n",
    "    y0_pred = X_bart_4.predict(x)\n",
    "    \n",
    "    y_pred = propensity * y0_pred + (1 - propensity) * y1_pred\n",
    "    y_true = y1 - y0\n",
    "    \n",
    "    mse = mean_squared_error(y_pred, y_true)\n",
    "    models.append((X_rf_0, X_rf_1, X_rf_3, X_rf_4))\n",
    "    MSE.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[31.68189511573245]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X-RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "could not allocate 7340032 bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7a14ac654b85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mX_rf_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mX_rf_4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 328\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    329\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1125\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\anaconda3\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.DepthFirstTreeBuilder.build\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._add_node\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_tree.pyx\u001b[0m in \u001b[0;36msklearn.tree._tree.Tree._resize_c\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32msklearn/tree/_utils.pyx\u001b[0m in \u001b[0;36msklearn.tree._utils.safe_realloc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: could not allocate 7340032 bytes"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "MSE = []\n",
    "for n in train_lens:\n",
    "    \n",
    "    x = simulate_feature_vec(n,d) \n",
    "    y1, y0 = simulate_y1(n,d)\n",
    "    w = simulate_assignment(propensity)\n",
    "    y_obs = generate_assigned_y(y1,y0,w)\n",
    "    eff_act = calculate_effect(y1, y0)\n",
    "    \n",
    "    X_0 = np.array([x[i] for i in range(len(w)) if not w[i]])\n",
    "    X_1 = np.array([x[i] for i in range(len(w)) if w[i]])\n",
    "\n",
    "    Y_0 = np.array([y0[i] for i in range(len(w)) if not w[i]])\n",
    "    Y_1 = np.array([y1[i] for i in range(len(w)) if  w[i]])\n",
    "    \n",
    "    X_rf_0 = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "    X_rf_1 = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "    \n",
    "    X_rf_0.fit(X_0, Y_0)\n",
    "    X_rf_1.fit(X_1, Y_1)\n",
    "    \n",
    "    D_1 = Y_1 - X_rf_0.predict(X_1)\n",
    "    D_0 = X_rf_1.predict(X_0) - Y_0\n",
    "\n",
    "    X_rf_3 = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "    X_rf_4 = RandomForestRegressor(random_state=123, n_estimators=100)\n",
    "    \n",
    "    X_rf_3.fit(X_1, D_1)\n",
    "    X_rf_4.fit(X_0, D_0)\n",
    "    \n",
    "    \n",
    "    y1_pred = X_rf_3.predict(x)\n",
    "    y0_pred = X_rf_4.predict(x)\n",
    "    \n",
    "    y_pred = propensity * y0_pred + (1 - propensity) * y1_pred\n",
    "    y_true = y1 - y0\n",
    "    \n",
    "    mse = mean_squared_error(y_pred, y_true)\n",
    "    models.append((X_rf_0, X_rf_1, X_rf_3, X_rf_4))\n",
    "    MSE.append(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
